# -*- coding: utf-8 -*-
"""Scraping B3 lista ações (old scraping)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12gU6XDMd3CdwICqgXlIf85ol3UaQSJ0X

#1 Setup do sistema
Serão feitas as instalações necessárias no sistema e a importação das bibliotecas

##1.1 Instalação do selenium e chromedriver
"""

# !apt install chromium-chromedriver
# !cp /usr/lib/chromium-browser/chromedriver /usr/bin
# !pip install selenium
#https://medium.com/analytics-vidhya/the-art-of-not-getting-blocked-how-i-used-selenium-python-to-scrape-facebook-and-tiktok-fd6b31dbe85f

"""##1.2 Imports e argumentos 
Import do selenium e adição dos argumentos necessários para o chromedriver rodar no Colab
"""

from time import sleep
import pandas as pd
from selenium import webdriver
import json

url_stock = 'https://sistemaswebb3-listados.b3.com.br/listedCompaniesPage/search?language=pt-br'
url_bdr = 'https://sistemaswebb3-listados.b3.com.br/listedCompaniesPage/search?language=pt-br&bdr='
url_fii = 'https://sistemaswebb3-listados.b3.com.br/fundsPage/7'
url_etf = 'https://sistemaswebb3-listados.b3.com.br/fundsPage/20'

def obter_codigos_b3():
  options = webdriver.ChromeOptions()
  options.add_argument('--headless')
  options.add_argument('--no-sandbox')
  options.add_argument('--disable-dev-shm-usage')
  #options.add_argument("--remote-debugging-port=9222")

  """##1.3 URLs"""


  """#2 Análise"""

  #Ações
  t = 1
  wd = webdriver.Chrome('chromedriver',options=options)
  wd.get(url_stock)
  sleep(3)
  wd.find_element('id', "nav-table-tab").click()
  sleep(t)
  df = pd.read_html(wd.page_source)[0].drop(['Segmento','Razão Social'], axis=1)
  #select_table.click()
  while True:
    wd.find_element('class name','pagination-next').click()
    sleep(t)
    df_pagina = pd.read_html(wd.page_source)[0].drop(['Segmento','Razão Social'], axis=1)
    print("Analisando até o código da ação "+df_pagina['Código'].iloc[-1])
    if df_pagina['Código'].iloc[-1] == df['Código'].iloc[-1]: break
    df = pd.concat([df, df_pagina]).reset_index().drop('index',axis=1)
    #break
  # #BDRs
  wd = webdriver.Chrome('chromedriver',options=options)
  wd.get(url_bdr)
  sleep(3)
  wd.find_element('id', "nav-table-tab").click()
  sleep(t)
  while True:
    df_pagina = pd.read_html(wd.page_source)[0].drop(['Segmento','Razão Social','Categoria'], axis=1)
    # print(df_pagina['Código'].iloc[-1], df['Código'].iloc[-1])
    print("Analisando até o código do BDR "+df_pagina['Código'].iloc[-1])
    if df_pagina['Código'].iloc[-1] == df['Código'].iloc[-1]: break
    df = pd.concat([df, df_pagina]).reset_index().drop('index',axis=1)
    wd.find_element('class name','pagination-next').click()
    sleep(t)
  
  #ETFs  
  wd = webdriver.Chrome('chromedriver',options=options)
  wd.get(url_etf)
  sleep(3)
  wd.find_element('id', "nav-table-tab").click()
  sleep(t)
  while True:
    df_pagina = pd.read_html(wd.page_source)[0].drop(['Segmento','Razão Social',], axis=1)
    print("Analisando até o código do ETF "+df_pagina['Código'].iloc[-1])
    if df_pagina['Código'].iloc[-1] == df['Código'].iloc[-1]: break
    df_pagina.columns=['Nome de Pregão','Código']
    df = pd.concat([df, df_pagina]).reset_index().drop('index',axis=1)
    wd.find_element('class name','pagination-next').click()
    sleep(t)
    
  #FIIs  
  wd = webdriver.Chrome('chromedriver',options=options)
  wd.get(url_fii)
  sleep(3)
  wd.find_element('id', "nav-table-tab").click()
  sleep(t)
  while True:
    df_pagina = pd.read_html(wd.page_source)[0].drop(['Segmento','Razão Social',], axis=1)
    print("Analisando até o código do FII "+df_pagina['Código'].iloc[-1])
    if df_pagina['Código'].iloc[-1] == df['Código'].iloc[-1]: break
    df_pagina.columns=['Nome de Pregão','Código']
    df = pd.concat([df, df_pagina]).reset_index().drop('index',axis=1)
    wd.find_element('class name','pagination-next').click()
    sleep(t)
    
    
  df.columns = ['Nome','Codigo']
  df['Nome'] = df['Nome'].apply(lambda x: x.replace(" ",""))
  return df#.set_index('Nome')

if __name__ == "__main__":
  # obter_codigos_b3().to_json('codigos_b3.json',orient='values')
  with open ('codigos_b3.json','w') as f:
    json.dump(obter_codigos_b3().set_index('Nome').to_dict(orient='dict'), f)
#df.to_csv('/content/codigos_b3.csv')